{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://machinelearningmastery.com/how-to-develop-convolutional-neural-network-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuring the IO structure:\n",
    "W_size=3\n",
    "st=4\n",
    "et=22\n",
    "Bin_size=1\n",
    "prediction_size=1\n",
    "n_features=282\n",
    "irows=int(W_size/Bin_size)\n",
    "icols=n_features\n",
    "orows=int(prediction_size/Bin_size)\n",
    "ocols=147\n",
    "nipd=int((et-st)/Bin_size)-irows-orows+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pennyworth/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "# Data Preparation\n",
    "import pandas as pd\n",
    "\n",
    "# Selecting data based on bin size\n",
    "if Bin_size==0.5:\n",
    "    df2 = pd.read_csv('/home/pennyworth/Documents/Bus/Data/from_R_19B_30min_n&f.csv',header =None)\n",
    "if Bin_size==1:\n",
    "    df2 = pd.read_csv('/home/pennyworth/Documents/Bus/Data/from_R_19B_1Hr_n&f.csv',header =None)\n",
    "    \n",
    "#Converting dataframe into matrix    \n",
    "dataset=df2.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import successful!\n"
     ]
    }
   ],
   "source": [
    "#Checking if the import is good to go:\n",
    "if len(dataset)-1==34*18/Bin_size:\n",
    "    print(\"Import successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 282), dtype=float64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(irows,orows)\n",
    "dataset[700:714]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IO Matrix creation successful!\n"
     ]
    }
   ],
   "source": [
    "# multivariate multi-step data preparation\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "#Split a multivariate sequence into samples and put them into X and y\n",
    "X, y = list(), list()\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    #print(n_steps_in,n_steps_out)\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :-2]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return None\n",
    "\n",
    "n_steps_in, n_steps_out = int(irows), int(orows)\n",
    "rows_pday=int((et-st)/Bin_size)\n",
    "\n",
    "i=1\n",
    "# convert into input/output\n",
    "# Need to change to 34 or 35 or whatever when nrows in dataset change\n",
    "for i in range(1,35):\n",
    "    todays_df=dataset[(i-1)*rows_pday+1:i*rows_pday+1]\n",
    "    split_sequences(todays_df, n_steps_in, n_steps_out)\n",
    "\n",
    "\n",
    "#Check if the io sample count is valid:\n",
    "if len(X[1][1])==n_features and nipd*34==len(X)==len(y) and len(y[1][0])==280:\n",
    "        print(\"IO Matrix creation successful!\")\n",
    "else:\n",
    "    print(\"IO Matrix creation unsuccessful!\",len(X[1][1])==n_features,nipd*34==len(X)==len(y),len(y[1][0])==280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.24045624, 0.23950137, 0.38706875, ..., 0.0918801 , 1.        ,\n",
       "        0.02313167],\n",
       "       [0.21217305, 0.28343602, 0.50255008, ..., 0.09123512, 1.        ,\n",
       "        0.07651246],\n",
       "       [0.05673372, 0.16196049, 0.18025789, ..., 0.03979822, 1.        ,\n",
       "        0.14190391],\n",
       "       ...,\n",
       "       [0.11917432, 0.46284269, 0.09528498, ..., 0.14025146, 1.        ,\n",
       "        0.81672598],\n",
       "       [0.29927743, 0.78598557, 0.8412775 , ..., 0.28696058, 1.        ,\n",
       "        0.85913405],\n",
       "       [0.24406702, 0.58756366, 0.57368792, ..., 0.24887576, 1.        ,\n",
       "        0.93060498]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    2,    3,    4,    5,    6,    7,    8,    9,   10,   11,\n",
       "         12,   13,   14,   15,   16,   17,   18,   19,   20,   21,   22,\n",
       "         23,   24,   25,   26,   27,   28,   29,   30,   31,   32,   33,\n",
       "         34,   35,   36,   37,   38,   39,   40,   41,   42,   43,   44,\n",
       "         45,   46,   47,   48,   49,   50,   51,   52,   53,   54,   55,\n",
       "         56,   57,   58,   59,   60,   61,   62,   63,   64,   65,   66,\n",
       "         67,   68,   69,   70,   71,   72,   73,   74,   75,   76,   77,\n",
       "         78,   79,   80,   81,   82,   83,   84,   85,   86,   87,   88,\n",
       "         89,   90,   91,   92,   93,   94,   95,   96,   97,   98,   99,\n",
       "        100,  101,  102,  103,  104,  105,  106,  107,  108,  109,  110,\n",
       "        111,  112,  113,  114,  115,  116,  117,  118,  119,  120,  121,\n",
       "        122,  123,  124,  125,  126,  127,  128,  129,  130,  131,  132,\n",
       "        133,  134,  135,  136,  137,  138,  139,  140,  141,  142,  143,\n",
       "        144,  145,  146,  147,  148,  149,  150,  151,  152,  153,  154,\n",
       "        155,  156,  157,  158,  159,  160,  161,  162,  163,  164,  165,\n",
       "        166,  167,  168,  169,  170,  171,  172,  173,  174,  175,  176,\n",
       "        177,  178,  179,  180,  181,  182,  183,  184,  185,  186,  187,\n",
       "        188,  189,  190,  191,  192,  193,  194,  195,  196,  197,  198,\n",
       "        199,  200,  201,  202,  203,  204,  205,  206,  207,  208,  209,\n",
       "        210,  211,  212,  213,  214,  215,  216,  217,  218,  219,  220,\n",
       "        221,  222,  223,  224,  225,  226,  227,  228,  229,  230,  231,\n",
       "        232,  233,  234,  235,  236,  237,  238,  239,  240,  241,  242,\n",
       "        243,  244,  245,  246,  247,  248,  249,  250,  251,  252,  253,\n",
       "        254,  255,  256,  257,  258,  259,  260,  261,  262,  263,  264,\n",
       "        265,  266,  267,  268,  269,  270,  271,  272,  273,  274,  275,\n",
       "        276,  277,  278,  279,  280,  281,  282,  283,  284,  285,  286,\n",
       "        287,  288,  289,  290,  291,  292,  293,  294,  295,  296,  297,\n",
       "        298,  299,  300,  301,  302,  303,  304,  305,  306,  307,  308,\n",
       "        309,  310,  311,  312,  313,  314,  315,  316,  317,  318,  319,\n",
       "        320,  321,  322,  323,  324,  325,  326,  327,  328,  329,  330,\n",
       "        331,  332,  333,  334,  335,  336,  337,  338,  339,  340,  341,\n",
       "        342,  343,  344,  345,  346,  347,  348,  349,  350,  351,  352,\n",
       "        353,  354,  355,  356,  357,  358,  359,  360,  361,  362,  363,\n",
       "        364,  365,  366,  367,  368,  369,  370,  371,  372,  373,  374,\n",
       "        375,  376,  377,  378,  379,  380,  381,  382,  383,  384,  385,\n",
       "        386,  387,  388,  389,  390,  391,  392,  393,  394,  395,  396,\n",
       "        397,  398,  399,  400,  401,  402,  403,  404,  405,  406,  407,\n",
       "        408,  409,  410,  411,  412,  413,  414,  415,  416,  417,  418,\n",
       "        419,  420,  421,  422,  423,  424,  425,  426,  427,  428,  429,\n",
       "        430,  431,  432,  433,  434,  435,  436,  437,  438,  439,  440,\n",
       "        441,  442,  443,  444,  445,  446,  447,  448,  449,  450,  451,\n",
       "        452,  453,  454,  455,  456,  457,  458,  459,  460,  461,  462,\n",
       "        463,  464,  465,  466,  467,  468,  469,  470,  471,  472,  473,\n",
       "        474,  475,  476,  477,  478,  479,  480,  481,  482,  483,  484,\n",
       "        485,  486,  487,  488,  489,  490,  491,  492,  493,  494,  495,\n",
       "        496,  497,  498,  499,  500,  501,  502,  503,  504,  505,  506,\n",
       "        507,  508,  509,  510,  511,  512,  513,  514,  515,  516,  517,\n",
       "        518,  519,  520,  521,  522,  523,  524,  525,  526,  527,  528,\n",
       "        529,  530,  531,  532,  533,  534,  535,  536,  537,  538,  539,\n",
       "        540,  541,  542,  543,  544,  545,  546,  547,  548,  549,  550,\n",
       "        551,  552,  553,  554,  555,  556,  557,  558,  559,  560,  561,\n",
       "        562,  563,  564,  565,  566,  567,  568,  569,  570,  571,  572,\n",
       "        573,  574,  575,  576,  577,  578,  579,  580,  581,  582,  583,\n",
       "        584,  585,  586,  587,  588,  589,  590,  591,  592,  593,  594,\n",
       "        595,  596,  597,  598,  599,  600,  601,  602,  603,  604,  605,\n",
       "        606,  607,  608,  609,  610,  611,  612,  613,  614,  615,  616,\n",
       "        617,  618,  619,  620,  621,  622,  623,  624,  625,  626,  627,\n",
       "        628,  629,  630,  631,  632,  633,  634,  635,  636,  637,  638,\n",
       "        639,  640,  641,  642,  643,  644,  645,  646,  647,  648,  649,\n",
       "        650,  651,  652,  653,  654,  655,  656,  657,  658,  659,  660,\n",
       "        661,  662,  663,  664,  665,  666,  667,  668,  669,  670,  671,\n",
       "        672,  673,  674,  675,  676,  677,  678,  679,  680,  681,  682,\n",
       "        683,  684,  685,  686,  687,  688,  689,  690,  691,  692,  693,\n",
       "        694,  695,  696,  697,  698,  699,  700,  701,  702,  703,  704,\n",
       "        705,  706,  707,  708,  709,  710,  711,  712,  713,  714,  715,\n",
       "        716,  717,  718,  719,  720,  721,  722,  723,  724,  725,  726,\n",
       "        727,  728,  729,  730,  731,  732,  733,  734,  735,  736,  737,\n",
       "        738,  739,  740,  741,  742,  743,  744,  745,  746,  747,  748,\n",
       "        749,  750,  751,  752,  753,  754,  755,  756,  757,  758,  759,\n",
       "        760,  761,  762,  763,  764,  765,  766,  767,  768,  769,  770,\n",
       "        771,  772,  773,  774,  775,  776,  777,  778,  779,  780,  781,\n",
       "        782,  783,  784,  785,  786,  787,  788,  789,  790,  791,  792,\n",
       "        793,  794,  795,  796,  797,  798,  799,  800,  801,  802,  803,\n",
       "        804,  805,  806,  807,  808,  809,  810,  811,  812,  813,  814,\n",
       "        815,  816,  817,  818,  819,  820,  821,  822,  823,  824,  825,\n",
       "        826,  827,  828,  829,  830,  831,  832,  833,  834,  835,  836,\n",
       "        837,  838,  839,  840,  841,  842,  843,  844,  845,  846,  847,\n",
       "        848,  849,  850,  851,  852,  853,  854,  855,  856,  857,  858,\n",
       "        859,  860,  861,  862,  863,  864,  865,  866,  867,  868,  869,\n",
       "        870,  871,  872,  873,  874,  875,  876,  877,  878,  879,  880,\n",
       "        881,  882,  883,  884,  885,  886,  887,  888,  889,  890,  891,\n",
       "        892,  893,  894,  895,  896,  897,  898,  899,  900,  901,  902,\n",
       "        903,  904,  905,  906,  907,  908,  909,  910,  911,  912,  913,\n",
       "        914,  915,  916,  917,  918,  919,  920,  921,  922,  923,  924,\n",
       "        925,  926,  927,  928,  929,  930,  931,  932,  933,  934,  935,\n",
       "        936,  937,  938,  939,  940,  941,  942,  943,  944,  945,  946,\n",
       "        947,  948,  949,  950,  951,  952,  953,  954,  955,  956,  957,\n",
       "        958,  959,  960,  961,  962,  963,  964,  965,  966,  967,  968,\n",
       "        969,  970,  971,  972,  973,  974,  975,  976,  977,  978,  979,\n",
       "        980,  981,  982,  983,  984,  985,  986,  987,  988,  989,  990,\n",
       "        991,  992,  993,  994,  995,  996,  997,  998,  999, 1000])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq=np.array([i for i in range(1,1001)])\n",
    "seq_list=seq.reshape(100,10)\n",
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na Matrices filtered out sucessfuly!\n"
     ]
    }
   ],
   "source": [
    "#Filtering the Na IO matrices out\n",
    "from math import isnan\n",
    "import numpy as np\n",
    "X_fil=np.array(X)\n",
    "y_fil=np.array(y)\n",
    "del_index=[]\n",
    "\n",
    "# Noting down the index of Na matricesin del_index \n",
    "for i in range(len(X_fil)):\n",
    "    del_index.append(np.any(np.isnan(X_fil[i])) or np.any(np.isnan(y_fil[i])))\n",
    "\n",
    "# Filtering out the Na matrices from y_fil and X_fil by indexing using a list\n",
    "y_fil=y_fil[list(~np.array(del_index))]\n",
    "X_fil=X_fil[list(~np.array(del_index))]\n",
    "\n",
    "# Check if the filtering is successful:\n",
    "Na_count=0\n",
    "for i in range(len(X_fil)):\n",
    "    if np.any(np.isnan(y_fil[i]))==True & np.any(np.isnan(X_fil[i]))==True:\n",
    "        Na_count=Na_count+1\n",
    "if Na_count==0:\n",
    "    print(\"Na Matrices filtered out sucessfuly!\")\n",
    "# y=np.array(y)\n",
    "# for el in y[list(~np.array(deathlist))]:\n",
    "#     print(np.any(np.isnan(Xtrial[i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510  I/O pairs available.\n"
     ]
    }
   ],
   "source": [
    "# Print number of IO Pairs available:\n",
    "print(len(y_fil),\" I/O pairs available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten output\n",
    "n_output = y_fil.shape[1] * y_fil.shape[2]\n",
    "y_fil = y_fil.reshape((y_fil.shape[0], n_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good to go!\n"
     ]
    }
   ],
   "source": [
    "# Check the number of features\n",
    "if n_features == X_fil.shape[2]:\n",
    "    print(\"Good to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.86543419e-02, 1.08914857e-01, 1.83544514e-01,\n",
       "       1.71919321e-01, 1.65658966e-01, 4.38183864e-01, 6.45631347e-01,\n",
       "       9.12602057e-01, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       2.85282818e-01, 2.82965558e-01, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 2.64321630e-01, 1.22309486e-01,\n",
       "       2.04509409e-01, 2.66856082e-01, 6.60065227e-01, 5.26189395e-01,\n",
       "       1.76680648e-01, 2.09703220e-01, 2.92368416e-01, 4.08191470e-01,\n",
       "       4.31609216e-01, 4.86386397e-01, 5.59498008e-01, 6.38697027e-01,\n",
       "       7.34000134e-01, 7.18822694e-01, 5.96487195e-01, 5.82187077e-01,\n",
       "       6.56233117e-01, 6.36347984e-01, 5.02851892e-01, 4.10973889e-01,\n",
       "       9.80020921e-02, 9.82909921e-02, 4.05132638e-01, 5.52442751e-01,\n",
       "       6.55613883e-01, 7.29110070e-01, 7.19170403e-01, 3.14989498e-01,\n",
       "       1.66410943e-01, 5.01613545e-01, 5.71713549e-01, 6.94405489e-01,\n",
       "       5.44127695e-01, 3.62969269e-01, 1.44834353e-01, 2.55702038e-01,\n",
       "       7.35222764e-01, 1.00000000e+00, 1.00000000e+00, 7.98002416e-01,\n",
       "       4.48746247e-01, 2.12630420e-01, 9.20893900e-02, 5.36066650e-02,\n",
       "       1.09017154e-01, 1.26746121e-01, 7.68515540e-02, 1.14245081e-01,\n",
       "       4.28927205e-01, 1.20607848e-01, 6.66954419e-02, 2.87041990e-02,\n",
       "       0.00000000e+00, 0.00000000e+00, 2.26779894e-02, 1.37826127e-02,\n",
       "       1.54711963e-02, 4.96818268e-02, 6.07680119e-02, 7.96408053e-02,\n",
       "       8.90776791e-02, 8.61861132e-02, 7.21383681e-02, 3.93765674e-02,\n",
       "       6.70344829e-02, 1.23922321e-01, 1.25241378e-01, 5.62408753e-02,\n",
       "       7.33731785e-02, 1.15671539e-01, 1.53700113e-01, 2.27518994e-01,\n",
       "       2.43518808e-01, 2.13714654e-01, 2.09087297e-01, 2.31122334e-01,\n",
       "       2.21017256e-01, 2.13688819e-01, 2.12534797e-01, 6.08851135e-02,\n",
       "       4.35601086e-01, 3.11294668e-01, 3.35327751e-01, 8.63132664e-02,\n",
       "       2.47051913e-01, 3.28061979e-01, 2.12557325e-01, 1.61826203e-01,\n",
       "       1.50702029e-01, 1.85292636e-01, 2.75878926e-01, 3.07526193e-01,\n",
       "       2.56580582e-01, 1.39068688e-01, 8.14112876e-01, 2.47795928e-01,\n",
       "       3.29550367e-01, 2.33479185e-01, 1.57319281e-01, 9.10260485e-02,\n",
       "       9.96564124e-02, 2.18684452e-02, 5.06730656e-02, 1.75759216e-01,\n",
       "       1.29634901e-01, 1.06680402e-01, 1.05551102e-01, 1.16012354e-01,\n",
       "       6.60909240e-02, 2.19673405e-02, 3.04239933e-03, 4.60498595e-04,\n",
       "       4.12963931e-03, 1.46766710e-01, 6.17355651e-01, 3.30013958e-01,\n",
       "       1.05876150e-01, 7.41399010e-02, 4.39539641e-02, 2.67605114e-01,\n",
       "       1.00000000e+00, 6.29442161e-01, 2.25390268e-01, 2.20372175e-01,\n",
       "       2.02046131e-01, 5.57345531e-01, 2.69486078e-01, 2.06230025e-01,\n",
       "       2.32433573e-01, 1.28143770e-01, 9.94994793e-02, 3.62668549e-01,\n",
       "       3.06491818e-01, 3.79810023e-01, 5.60062472e-01, 6.57194352e-01,\n",
       "       6.43813255e-01, 6.23243430e-01, 4.97399597e-01, 3.18076336e-01,\n",
       "       7.79296319e-02, 9.62632868e-02, 1.48155057e-01, 3.30991988e-02,\n",
       "       1.37460806e-02, 6.97688186e-03, 7.52822083e-02, 6.17247481e-02,\n",
       "       1.00000000e+00, 4.05949599e-01, 3.30975585e-01, 7.66327382e-02,\n",
       "       1.78512084e-01, 2.57350944e-01, 2.40390762e-01, 2.11784854e-01,\n",
       "       3.41131604e-01, 7.06683096e-02, 2.61473029e-01, 4.30599591e-01,\n",
       "       3.99323742e-01, 3.45712553e-01, 5.28261004e-01, 5.75045114e-01,\n",
       "       4.12402831e-01, 3.89059308e-01, 2.59522896e-01, 8.99269591e-03,\n",
       "       1.49582536e-02, 1.75476649e-01, 1.28665641e-01, 2.78978987e-02,\n",
       "       3.24259575e-02, 6.81367332e-02, 7.67658110e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 9.93278025e-02, 3.84490975e-01,\n",
       "       5.41451004e-01, 4.86210566e-02, 0.00000000e+00, 2.04664947e-02,\n",
       "       6.93732070e-04, 0.00000000e+00, 0.00000000e+00, 2.78707386e-01,\n",
       "       9.08887269e-02, 1.38519207e-02, 1.83343500e-01, 7.21719577e-01,\n",
       "       9.12404152e-01, 9.55504128e-01, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 7.71735833e-01, 7.05905483e-01,\n",
       "       7.02650248e-01, 6.79836909e-01, 4.78588645e-01, 1.37485649e-01,\n",
       "       8.42278520e-02, 1.40337971e-02, 5.70038661e-03, 3.19241946e-02,\n",
       "       1.15950614e-02, 7.26163884e-03, 5.18956924e-03, 3.31336066e-03,\n",
       "       5.67093128e-03, 2.39863095e-01, 3.86492593e-01, 1.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       2.77939011e-01, 5.06397918e-01, 5.37146951e-01, 4.06915433e-01,\n",
       "       1.59107917e-01, 3.11005647e-01, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 8.38676805e-01, 3.73606182e-01,\n",
       "       4.51363648e-01, 3.59620344e-01, 1.26944482e-01, 1.92321538e-02,\n",
       "       0.00000000e+00, 1.81909182e-01, 6.25312659e-02, 3.62599194e-02,\n",
       "       3.51204179e-02, 4.39881413e-02, 2.84742353e-01, 1.38179919e-01,\n",
       "       3.94391809e-02, 0.00000000e+00, 0.00000000e+00, 7.40546114e-02,\n",
       "       1.00000000e+00, 1.00000000e+00, 5.38629157e-01, 4.09508343e-01,\n",
       "       3.55025203e-01, 3.26637922e-01, 3.45499793e-01, 3.71496000e-01,\n",
       "       4.29559703e-01, 3.34779547e-01, 1.50080145e-01, 7.91964914e-02,\n",
       "       0.00000000e+00, 4.80427046e-02])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fil[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splitting done!\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test sets\n",
    "test_size=7\n",
    "train_end=(34-test_size)*(rows_pday-irows-orows+1)\n",
    "msk=[]\n",
    "for i in range(34*(rows_pday-irows-orows+1)):\n",
    "    if i<=train_end:\n",
    "        msk.append(True)\n",
    "    else:\n",
    "        msk.append(False)\n",
    "msk=np.asarray(msk)\n",
    "X_train = X_fil[msk]\n",
    "y_train = y_fil[msk]\n",
    "X_test = X_fil[~msk]\n",
    "y_test = y_fil[~msk]\n",
    "print(\"Dataset splitting done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number or epochs: 10\n",
      "Number of input features: 282\n",
      "Number of output features: 280\n",
      "Bin size: 1\n",
      "Window size: 3\n",
      "Number of I/O pairs available: 510\n",
      "104/104 [==============================] - 0s 55us/step\n",
      "Model Mape loss: 2806901.40625\n",
      "104/104 [==============================] - 0s 93us/step\n",
      "Model MSE loss (Minimized): 0.0358154598910075\n",
      "104/104 [==============================] - 0s 60us/step\n",
      "RMSE loss: 0.18924972890603436\n"
     ]
    }
   ],
   "source": [
    "# multivariate output multi-step 1d cnn example\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(irows, n_features)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(n_output))\n",
    "model.compile(optimizer='adam', loss=['mse'],metrics=[\"mape\"])\n",
    "epochno=10\n",
    "# fit model\n",
    "history=model.fit(X_train, y_train, epochs=epochno, verbose=0, validation_data = (X_test, y_test))\n",
    "print(\"Number or epochs:\",epochno)\n",
    "print(\"Number of input features:\",n_features)\n",
    "print(\"Number of output features:\",n_output)\n",
    "print(\"Bin size:\",Bin_size)\n",
    "print(\"Window size:\",W_size)\n",
    "print(\"Number of I/O pairs available:\",len(y_fil))\n",
    "print(\"Model Mape loss:\",model.evaluate(X_test,y_test)[1])\n",
    "print(\"Model MSE loss (Minimized):\",model.evaluate(X_test,y_test)[0])\n",
    "print(\"RMSE loss:\",np.sqrt(model.evaluate(X_test,y_test)[0]))\n",
    "\n",
    "# Demonstrate Prediction\n",
    "# x_input = array([[60, 65, 125], [70, 75, 145], [80, 85, 165]])\n",
    "# x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "# yhat = model.predict(x_input, verbose=0)\n",
    "# print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_mean_absolute_percentage_error', 'loss', 'mean_absolute_percentage_error'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "%matplotlib inline\n",
    "\n",
    "print(history.history.keys())\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss (MSE)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "#axes = plt.gca()\n",
    "#axes.set_ylim([7500,0.2*100000])\n",
    "#axes.set_xlim([1500,3000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history=model.fit(X, y, epochs=3000, verbose=1)\n",
    "#model.evaluate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# #from plotnine import *\n",
    "# rn=random.randint(1,150)\n",
    "# # demonstrate prediction\n",
    "# x_input = X[rn]\n",
    "# y_output = y[rn]\n",
    "# x_input = x_input.reshape((1, n_steps, n_features))\n",
    "# yhat = model.predict(x_input, verbose=1)\n",
    "# pdt=yhat[0]\n",
    "# act=y_output\n",
    "# print(len(pdt))\n",
    "# print(len(act))\n",
    "# #library(ggplot2)\n",
    "# #ggplot(, aes(x = drat, y = mpg)) + geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7d5c43c1ffbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ERROR!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mnorm_pdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm_act\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_pdt_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-7d5c43c1ffbc>\u001b[0m in \u001b[0;36mget_pdt_act\u001b[0;34m(ind)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#print(ind)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Demonstrate Prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mirows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot a random Prediction vs actual travel time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "\n",
    "#function to get the act and pdt values of a specified sample in the test set\n",
    "def get_pdt_act(ind):\n",
    "    #print(ind)\n",
    "    # Demonstrate Prediction\n",
    "    x_input = X_test[ind]\n",
    "    x_input = x_input.reshape((1, irows, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "    y_output = y_test[ind]\n",
    "    #print(len(yhat[0]))\n",
    "    pdt=yhat[0]\n",
    "    act=y_output\n",
    "    if len(pdt)!=len(act):\n",
    "        print(\"ERROR!\")\n",
    "    return pdt,act\n",
    "norm_pdt,norm_act=get_pdt_act(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dataset[4][:5])\n",
    "print(\"\\n\\n \")\n",
    "print(norm_act[:5])\n",
    "#print(y_test[1][:5])\n",
    "\n",
    "for i in range(100):\n",
    "    if (norm_act==dataset[i][:280])[0]==True:\n",
    "        print(i)\n",
    "        print(dataset[i][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[4][:280]==norm_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'norm_pdt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6a8223bebaa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mleg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mplot_this\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_pdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm_act\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'norm_pdt' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "def plot_this(pdt_plt,act_plt):\n",
    "    x=list(range(1,len(pdt_plt)+1))\n",
    "    plt.plot(x, pdt_plt[0:], color='g',label=\"Predicted\")\n",
    "    plt.plot(x, act_plt[0:], color='orange',label=\"Actual\")\n",
    "    plt.xlabel('Segments')\n",
    "    plt.ylabel('Travel time (s)')\n",
    "    plt.title('Predicted vs Actual')\n",
    "    axes = plt.gca()\n",
    "    #axes.set_ylim([0,180])\n",
    "    axes.set_xlim([-2,len(pdt_plt)+10])\n",
    "    leg = plt.legend();\n",
    "    plt.show()\n",
    "plot_this(norm_pdt,norm_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the IO values and then determining MSE and shit\n",
    "import pandas as pd\n",
    "\n",
    "# Selecting data min-max data\n",
    "Minmax = pd.read_csv('/home/pennyworth/Documents/Bus/Data/Minmax.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'norm_pdt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3128a3e9ad6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpdt_cor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mact_cor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mdenorm_pdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdenorm_act\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdenormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_pdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnorm_act\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mplot_this\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenorm_pdt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdenorm_act\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'norm_pdt' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def denormalize(nor_pdt,nor_act):\n",
    "    pdt_cor=[i for i in range(280)]\n",
    "    act_cor=[i for i in range(280)]\n",
    "    i=0\n",
    "    for col in Minmax.drop([\"V281\"],axis=1):\n",
    "        mn=Minmax[col][1]\n",
    "        mx=Minmax[col][0]\n",
    "        pdt_cor[i]=(nor_pdt[i]*(mx - mn))+mn\n",
    "        act_cor[i]=(nor_act[i]*(mx - mn))+mn\n",
    "        i=i+1\n",
    "    return pdt_cor,act_cor\n",
    "\n",
    "denorm_pdt,denorm_act=denormalize(norm_pdt,norm_act)    \n",
    "plot_this(denorm_pdt,denorm_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "#function to get errror for any pdt and act\n",
    "def get_error_pdt_act(pdt_err,act_err,printing=False):\n",
    "    if printing==True:\n",
    "        print(\"MSE Error:\",mean_squared_error(pdt_err,act_err))\n",
    "        print(\"RMSE Error:\",np.sqrt(mean_squared_error(pdt_err,act_err)))\n",
    "        print(\"MAPE Error:\",mean_absolute_percentage_error(pdt_err,act_err))\n",
    "    mse=mean_squared_error(pdt_err,act_err)\n",
    "    rmse=np.sqrt(mean_squared_error(pdt_err,act_err))\n",
    "    mape=mean_absolute_percentage_error(pdt_err,act_err)\n",
    "    return mse,rmse,mape\n",
    "\n",
    "get_error_pdt_act(denorm_pdt,denorm_act,False) \n",
    "print(\"MSE Error:\",mean_squared_error(denorm_pdt,denorm_act))\n",
    "print(\"RMSE Error:\",np.sqrt(mean_squared_error(denorm_pdt,denorm_act)))\n",
    "print(\"MAPE Error:\",mean_absolute_percentage_error(denorm_pdt,denorm_act))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating over all tensors in test set\n",
    "#Check if lengths match:\n",
    "if X_test.shape[0]==y_test.shape[0]:\n",
    "    print(\"Good to go!\")\n",
    "else:\n",
    "    print(\"Lengths dont match!\")\n",
    "\n",
    "MSE_list=[]\n",
    "RMSE_list=[]\n",
    "MAPE_list=[]\n",
    "pdt_list=[]\n",
    "act_list=[]\n",
    "\n",
    "total_test=X_test.shape[0]\n",
    "for ind in range(total_test):\n",
    "    norm_pdt,norm_act=get_pdt_act(ind)\n",
    "    denorm_pdt,denorm_act=denormalize(norm_pdt,norm_act)\n",
    "    pdt_list.append(denorm_pdt)\n",
    "    act_list.append(denorm_act)\n",
    "    MSE_list.append(get_error_pdt_act(denorm_pdt,denorm_act)[0])\n",
    "    RMSE_list.append(get_error_pdt_act(denorm_pdt,denorm_act)[1])\n",
    "    MAPE_list.append(get_error_pdt_act(denorm_pdt,denorm_act)[2])\n",
    "\n",
    "mean_MSE=sum(MSE_list)/len(MSE_list)\n",
    "mean_RMSE=sum(RMSE_list)/len(RMSE_list)\n",
    "mean_MAPE=sum(MAPE_list)/len(MAPE_list)    \n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Model - 2\")\n",
    "print(\"Overall MSE\",mean_MSE)\n",
    "print(\"Overall RMSE\",mean_RMSE)\n",
    "print(\"Overall MAPE\",mean_MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe out of the tt lists\n",
    "predicted_df=pd.DataFrame(pdt_list)\n",
    "actual_df=pd.DataFrame(act_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the dataframes as csv tables.\n",
    "predicted_df.to_csv(\"Model2_pdt.csv\")\n",
    "actual_df.to_csv(\"Model2_act.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
